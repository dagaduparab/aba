{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Dhadge Yash Kailas\n",
    "Roll No : 9019\n",
    "Class : BE-IT\n",
    "Course : Deep Learning\n",
    "\n",
    "Problem Statement :\n",
    "    Implement the Continuous Bag of Words (CBOW) Model. Stages can be:\n",
    "        a. Data preparation\n",
    "        b. Generate training data\n",
    "        c. Train model\n",
    "        d. Output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sCVfqccTjpe1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action = 'ignore')\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "# import bs4 as bs\n",
    "# import urllib.request\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pL8XSt-9j-du",
    "outputId": "1f30e79a-2180-42cb-8dc9-f936f66b5e7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Niranjan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Niranjan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "#Divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences\n",
    "nltk.download('stopwords')\n",
    "#Natural Language Toolkit(Stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nIlNgNVJkX9J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are about to study the idea of a computational process.\\nComputational processes are abstract beings that inhabit computers.\\nAs they evolve, processes manipulate other abstract things called data.\\nThe evolution of a process is directed by a pattern of rules\\ncalled a program. People create programs to direct processes. In effect,\\nwe conjure the spirits of the computer with our spells'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells\"\"\"\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation Of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01) Cleaning Of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4n82Aq2Vk1pa",
    "outputId": "6eb5e040-f83e-4250-b8ff-21bf3fad929a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are about to study the idea of computational process Computational processes are abstract beings that inhabit computers As they evolve processes manipulate other abstract things called data The evolution of process is directed by pattern of rules called program People create programs to direct processes In effect we conjure the spirits of the computer with our spells\n"
     ]
    }
   ],
   "source": [
    "#Remove one letter words\n",
    "sentences = re.sub('[^A-Za-z0-9]+', ' ', sentences)\n",
    "\n",
    "#Remove special characters\n",
    "sentences = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentences).strip()\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02) Converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tgxIevXDnIdI"
   },
   "outputs": [],
   "source": [
    "#Convert all letters to lowercase\n",
    "sentences = sentences.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03) Tokenize sentences and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWGXxR0mm2Va",
    "outputId": "76998e5e-f72a-4240-fdbd-3ec4544907ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we are about to study the idea of computational process computational processes are abstract beings that inhabit computers as they evolve processes manipulate other abstract things called data the evolution of process is directed by pattern of rules called program people create programs to direct processes in effect we conjure the spirits of the computer with our spells']\n"
     ]
    }
   ],
   "source": [
    "#Tokenize sentences (Tokenization is the act of breaking up a sequence of strings into pieces)\n",
    "all_sent=nltk.sent_tokenize(sentences)\n",
    "print(all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eD8aAL5knrSc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['we',\n",
       "  'are',\n",
       "  'about',\n",
       "  'to',\n",
       "  'study',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'computational',\n",
       "  'process',\n",
       "  'computational',\n",
       "  'processes',\n",
       "  'are',\n",
       "  'abstract',\n",
       "  'beings',\n",
       "  'that',\n",
       "  'inhabit',\n",
       "  'computers',\n",
       "  'as',\n",
       "  'they',\n",
       "  'evolve',\n",
       "  'processes',\n",
       "  'manipulate',\n",
       "  'other',\n",
       "  'abstract',\n",
       "  'things',\n",
       "  'called',\n",
       "  'data',\n",
       "  'the',\n",
       "  'evolution',\n",
       "  'of',\n",
       "  'process',\n",
       "  'is',\n",
       "  'directed',\n",
       "  'by',\n",
       "  'pattern',\n",
       "  'of',\n",
       "  'rules',\n",
       "  'called',\n",
       "  'program',\n",
       "  'people',\n",
       "  'create',\n",
       "  'programs',\n",
       "  'to',\n",
       "  'direct',\n",
       "  'processes',\n",
       "  'in',\n",
       "  'effect',\n",
       "  'we',\n",
       "  'conjure',\n",
       "  'the',\n",
       "  'spirits',\n",
       "  'of',\n",
       "  'the',\n",
       "  'computer',\n",
       "  'with',\n",
       "  'our',\n",
       "  'spells']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Break sentences into words\n",
    "all_words=[nltk.word_tokenize(i) for i in all_sent]\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04) Removal Of Stopwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "r_O3qiB5oa_U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['study',\n",
       "  'idea',\n",
       "  'computational',\n",
       "  'process',\n",
       "  'computational',\n",
       "  'processes',\n",
       "  'abstract',\n",
       "  'beings',\n",
       "  'inhabit',\n",
       "  'computers',\n",
       "  'evolve',\n",
       "  'processes',\n",
       "  'manipulate',\n",
       "  'abstract',\n",
       "  'things',\n",
       "  'called',\n",
       "  'data',\n",
       "  'evolution',\n",
       "  'process',\n",
       "  'directed',\n",
       "  'pattern',\n",
       "  'rules',\n",
       "  'called',\n",
       "  'program',\n",
       "  'people',\n",
       "  'create',\n",
       "  'programs',\n",
       "  'direct',\n",
       "  'processes',\n",
       "  'effect',\n",
       "  'conjure',\n",
       "  'spirits',\n",
       "  'computer',\n",
       "  'spells']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "  all_words[i]=[w for w in all_words[i] if w not in stopwords.words('english')]\n",
    "data =all_words\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-hjheB5ooGq",
    "outputId": "778c12c5-f32f-4435-cdf5-bbbe80788f4e"
   },
   "outputs": [],
   "source": [
    "#Training model using gensim\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1,size = 52, window = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgfeXr8jovHn",
    "outputId": "e769b387-e4f0-4be1-9b17-f46002968ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data', 0.44202977418899536)\n",
      "('create', 0.32048046588897705)\n",
      "('pattern', 0.3090987503528595)\n",
      "('inhabit', 0.2220422327518463)\n",
      "('direct', 0.15680371224880219)\n",
      "('programs', 0.15108151733875275)\n",
      "('conjure', 0.1508389562368393)\n",
      "('study', 0.10908053815364838)\n",
      "('evolution', 0.10641119629144669)\n",
      "('effect', 0.10517579317092896)\n"
     ]
    }
   ],
   "source": [
    "#Finding similar words to given word\n",
    "word='computer'\n",
    "#v1=model1.wv[word]\n",
    "similar_words=model1.wv.most_similar(word)\n",
    "for x in similar_words:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvQTxKJ2qfQW",
    "outputId": "74bcb035-0945-4438-d7ca-0b40b81b35b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['study', 'idea', 'computational', 'process', 'computational', 'processes', 'abstract', 'beings', 'inhabit', 'computers', 'evolve', 'processes', 'manipulate', 'abstract', 'things', 'called', 'data', 'evolution', 'process', 'directed', 'pattern', 'rules', 'called', 'program', 'people', 'create', 'programs', 'direct', 'processes', 'effect', 'conjure', 'spirits', 'computer', 'spells']\n"
     ]
    }
   ],
   "source": [
    "split_data = data[0]\n",
    "print(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWLH1oMpq1Or",
    "outputId": "13040971-467f-4813-f12b-b23d36db1182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['study', 'idea', 'process', 'computational'], 'computational'), (['idea', 'computational', 'computational', 'processes'], 'process'), (['computational', 'process', 'processes', 'abstract'], 'computational'), (['process', 'computational', 'abstract', 'beings'], 'processes'), (['computational', 'processes', 'beings', 'inhabit'], 'abstract'), (['processes', 'abstract', 'inhabit', 'computers'], 'beings'), (['abstract', 'beings', 'computers', 'evolve'], 'inhabit'), (['beings', 'inhabit', 'evolve', 'processes'], 'computers'), (['inhabit', 'computers', 'processes', 'manipulate'], 'evolve'), (['computers', 'evolve', 'manipulate', 'abstract'], 'processes'), (['evolve', 'processes', 'abstract', 'things'], 'manipulate'), (['processes', 'manipulate', 'things', 'called'], 'abstract'), (['manipulate', 'abstract', 'called', 'data'], 'things'), (['abstract', 'things', 'data', 'evolution'], 'called'), (['things', 'called', 'evolution', 'process'], 'data'), (['called', 'data', 'process', 'directed'], 'evolution'), (['data', 'evolution', 'directed', 'pattern'], 'process'), (['evolution', 'process', 'pattern', 'rules'], 'directed'), (['process', 'directed', 'rules', 'called'], 'pattern'), (['directed', 'pattern', 'called', 'program'], 'rules'), (['pattern', 'rules', 'program', 'people'], 'called'), (['rules', 'called', 'people', 'create'], 'program'), (['called', 'program', 'create', 'programs'], 'people'), (['program', 'people', 'programs', 'direct'], 'create'), (['people', 'create', 'direct', 'processes'], 'programs'), (['create', 'programs', 'processes', 'effect'], 'direct'), (['programs', 'direct', 'effect', 'conjure'], 'processes'), (['direct', 'processes', 'conjure', 'spirits'], 'effect'), (['processes', 'effect', 'spirits', 'computer'], 'conjure'), (['effect', 'conjure', 'computer', 'spells'], 'spirits')]\n"
     ]
    }
   ],
   "source": [
    "#Preparing list of context words\n",
    "\n",
    "Context_Target_Data = []\n",
    "for i in range(2, len(split_data) - 2):\n",
    "    context = [split_data[i - 2], split_data[i - 1], split_data[i+1], split_data[i + 2]]\n",
    "    target = split_data[i]\n",
    "    Context_Target_Data.append((context, target))\n",
    "print(Context_Target_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qN_pKTDfr0PH",
    "outputId": "56cc8319-b0b6-4b65-c925-ebbe3a8d5e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['study', 'idea', 'process', 'computational'] computational\n",
      "[('process', 0.03571443), ('abstract', 0.03571441), ('computational', 0.035714366), ('idea', 0.03571435), ('rules', 0.035714332), ('programs', 0.03571432), ('direct', 0.03571432), ('processes', 0.03571432), ('create', 0.035714317), ('pattern', 0.03571429)]\n"
     ]
    }
   ],
   "source": [
    "#Predicting current word from context words\n",
    "i=0\n",
    "print(Context_Target_Data[i][0],Context_Target_Data[i][1])\n",
    "print(model1.predict_output_word(Context_Target_Data[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
